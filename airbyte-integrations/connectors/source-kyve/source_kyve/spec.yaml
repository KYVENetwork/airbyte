documentationUrl: https://docs.airbyte.com/integrations/sources/kyve
connectionSpecification:
  $schema: http://json-schema.org/draft-07/schema#
  title: KYVE Spec
  type: object
  required:
    - pool_ids
    - start_ids
    - url_base
  additionalProperties: true
  properties:
    pool_ids:
      type: string
      title: Pool-IDs
      description: The IDs of the KYVE storage pool you want to archive. (Comma separated)
      examples:
        - "0"
        - "0,1"
    start_ids:
      type: string
      title: Bundle-Start-IDs
      description:
        The start-id defines, from which bundle id the pipeline should
        start to extract the data. (Comma separated)
      examples:
        - "0"
        - "0,0"
        - "100"
    url_base:
      type: string
      title: KYVE-API URL Base
      description: URL to the KYVE Chain API.
      default: https://api.kyve.network
      examples:
        - https://api.kaon.kyve.network/
        - https://api.korellia.kyve.network/
    start_keys:
      type: string
      title: Start keys
      description:
        The start key defines, from which key the pipeline should
        start to extract the data. Only recommended when the sync should 
        start at a specific key with a predefined Bundle-Start-ID to prevent 
        inefficiency. Right now, this is only supported for pools using the 
        kyvejs/tendermint or kyvejs/tendermint-bsync runtime. (Comma separated)
      examples:
        - "0"
        - "50"
        - "0,0"
    end_keys:
      type: string
      title: End keys
      description:
        The end key defines, until which key the pipeline should
        extract the data. Only recommended when the sync should
        end at a specific key to prevent unnecessary data traffic. 
        Right now, this is only supported for pools using the kyvejs/tendermint 
        or kyvejs/tendermint-bsync runtime. (Comma separated)
      examples:
        - "100"
        - "20,10"
    data_item_size_limit:
      type: integer
      title: Data item size limit (MB)
      description:
        The data item size limit enables the chunking of data item's value
        into smaller pieces to ensure that you can load it into your data destination
        even when the data item can be bigger than the destination size limit. It's disabled
        by default and reduces the loading speed of the connector significantly and it's enabled
        by setting a value. The values are chunked into (data_size_limit / 20) MB big chunks. 
        (It is recommended to keep the limit smaller than the actual limit. Example -> The 
        BigQuery row limit is 100MB, which is why it would be set to 80MB here.)
      examples:
        - "100"
        - "50"
    enable_tendermint_normalization:
      type: boolean
      title: Enable Tendermint normalization
      default: false
      description:
        Normalizes block results object and writes each event of begin_block_events, end_block_events 
        and txs_results in one row.
    max_pages:
      type: integer
      description:
        The maximum amount of pages to go trough. Set to 'null' for all
        pages.
      airbyte_hidden: true
    page_size:
      type: integer
      description:
        The pagesize for pagination, smaller numbers are used in integration
        tests.
      airbyte_hidden: true
